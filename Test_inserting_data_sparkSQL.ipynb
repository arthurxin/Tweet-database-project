{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e46b4c5",
   "metadata": {},
   "source": [
    "# ———————————Recursion—————————————\n",
    "## from hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a6937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updata_mongodb(json_data,timestamp):\n",
    "    if \"timestamp\" in json_data:\n",
    "        ctime = json_data[\"timestamp\"]\n",
    "    else:\n",
    "        ctime = timestamp\n",
    "    update_dict = {}\n",
    "    \n",
    "    # tweet_type\n",
    "    reply_status = False\n",
    "    retweet_status = False\n",
    "    quote_status = False\n",
    "    try:\n",
    "        if json_data[\"in_reply_to_status_id_str\"] != None:\n",
    "            reply_status = True\n",
    "    except KeyError:\n",
    "        pass      \n",
    "    if \"quoted_status\" in json_data:\n",
    "        quote_status = True\n",
    "    if \"retweeted_status\" in json_data:\n",
    "        retweet_status = True\n",
    "    \n",
    "    # format update_dict\n",
    "    try_insert_dict(update_dict,\"tweet_id\",json_data[\"id_str\"])\n",
    "    try:\n",
    "        if json_data[\"truncated\"]==False:\n",
    "            try_insert_dict(update_dict,\"text\",json_data[\"text\"])\n",
    "            try_insert_dict(update_dict,\"hashtags\",json_data[\"entities\"][\"hashtags\"])\n",
    "        elif json_data[\"truncated\"]==True:\n",
    "            try_insert_dict(update_dict,\"text\",json_data[\"extended_tweet\"][\"full_text\"])\n",
    "            try_insert_dict(update_dict,\"hashtags\",json_data[\"extended_tweet\"][\"entities\"][\"hashtags\"])\n",
    "    except KeyError:\n",
    "            pass\n",
    "    \n",
    "    try_insert_dict(update_dict,\"userid\",json_data[\"user\"][\"id_str\"])\n",
    "    try_insert_dict(update_dict,\"username\",json_data[\"user\"][\"name\"])\n",
    "    try_insert_dict(update_dict,\"user_screen_name\",json_data[\"user\"][\"screen_name\"])\n",
    "    \n",
    "    try_insert_dict(update_dict,\"quote_count\",json_data[\"quote_count\"])\n",
    "    try_insert_dict(update_dict,\"reply_count\",json_data[\"reply_count\"])\n",
    "    try_insert_dict(update_dict,\"retweet_count\",json_data[\"retweet_count\"])\n",
    "    try_insert_dict(update_dict,\"favorite_count\",json_data[\"favorite_count\"])\n",
    "    try_insert_dict(update_dict,\"timestamp_ms\",ctime)\n",
    "    \n",
    "    if reply_status == True:\n",
    "        try_insert_dict(update_dict,\"reply_to_tweeet_id\",json_data[\"in_reply_to_status_id_str\"])\n",
    "        try_insert_dict(update_dict,\"reply_to_user_id\",json_data[\"in_reply_to_user_id_str\"])\n",
    "        try_insert_dict(update_dict,\"reply_to_user_name\",json_data[\"in_reply_to_screen_name\"])\n",
    "    if quote_status == True:\n",
    "        try_insert_dict(update_dict,\"quote_to_tweet_id\",json_data[\"quoted_status_id_str\"])\n",
    "    if retweet_status == True:\n",
    "        try_insert_dict(update_dict,\"retweet_to_tweet_id\",json_data[\"retweeted_status\"][\"id_str\"])\n",
    "    \n",
    "    # reply table    \n",
    "    if reply_status == True:\n",
    "        exist_status = False\n",
    "        doc = reply_col.find({\"tweet_id\":json_data[\"id_str\"]})\n",
    "        for x in doc:\n",
    "            exist_status = True\n",
    "        if exist_status == False:\n",
    "            reply_col.insert_one(update_dict)\n",
    "        else:\n",
    "            reply_col.replace_one(\n",
    "                {\"tweet_id\":json_data[\"id_str\"],\"timestamp_ms\":{\"$lt\":ctime}},\n",
    "                update_dict,\n",
    "                upsert=False\n",
    "                  )\n",
    "    \n",
    "    \n",
    "    # quote table\n",
    "    if quote_status == True:\n",
    "        exist_status = False\n",
    "        doc = quote_col.find({\"tweet_id\":json_data[\"id_str\"]})\n",
    "        for x in doc:\n",
    "            exist_status = True\n",
    "        if exist_status == False:\n",
    "            quote_col.insert_one(update_dict)\n",
    "        else:\n",
    "            quote_col.replace_one(\n",
    "                {\"tweet_id\":json_data[\"id_str\"],\"timestamp_ms\":{\"$lt\":ctime}},\n",
    "                update_dict,\n",
    "                upsert=False\n",
    "                  )      \n",
    "        \n",
    "        \n",
    "    # retweet table\n",
    "    if retweet_status == True:\n",
    "        exist_status = False\n",
    "        doc = retweet_col.find({\"tweet_id\":json_data[\"id_str\"]})\n",
    "        for x in doc:\n",
    "            exist_status = True\n",
    "        if exist_status == False:\n",
    "            retweet_col.insert_one(update_dict)\n",
    "        else:\n",
    "            retweet_col.replace_one(\n",
    "                {\"tweet_id\":json_data[\"id_str\"],\"timestamp_ms\":{\"$lt\":ctime}},\n",
    "                update_dict,\n",
    "                upsert=False\n",
    "                  ) \n",
    "            \n",
    "            \n",
    "    # origin table:\n",
    "    if (reply_status==False) and (quote_status==False) and (retweet_status==False):\n",
    "        exist_status = False\n",
    "        doc = origin_col.find({\"tweet_id\":json_data[\"id_str\"]})\n",
    "        for x in doc:\n",
    "            exist_status = True\n",
    "        if exist_status == False:\n",
    "            origin_col.insert_one(update_dict)\n",
    "        else:\n",
    "            origin_col.replace_one(\n",
    "                {\"tweet_id\":json_data[\"id_str\"],\"timestamp_ms\":{\"$lt\":ctime}},\n",
    "                update_dict,\n",
    "                upsert=False\n",
    "                  ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44e5dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_upload(json_data,excut_function,timestamp):\n",
    "    reply_status = False\n",
    "    retweet_status = False\n",
    "    quote_status = False\n",
    "    # reply status \n",
    "    try:\n",
    "        if json_data[\"in_reply_to_status_id_str\"] != None:\n",
    "            reply_status = True\n",
    "    except KeyError:\n",
    "        pass  \n",
    "    # quote status \n",
    "    if \"quoted_status\" in json_data:\n",
    "        quote_status = True\n",
    "    # retweet status\n",
    "    if \"retweeted_status\" in json_data:\n",
    "        retweet_status = True  \n",
    "    \n",
    "    if (reply_status==False) and (quote_status==False) and (retweet_status==False):\n",
    "        excut_function(json_data,timestamp)\n",
    "    elif reply_status==True:\n",
    "        excut_function(json_data,timestamp)\n",
    "    elif quote_status==True:\n",
    "        recursive_upload(json_data[\"quoted_status\"],excut_function,timestamp)\n",
    "        excut_function(json_data,timestamp)\n",
    "    elif retweet_status==True:\n",
    "        recursive_upload(json_data[\"retweeted_status\"],excut_function,timestamp)\n",
    "        excut_function(json_data,timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058b4d17",
   "metadata": {},
   "source": [
    "# ———————————start from here—————————————"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2cfdf5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, SQLContext, Row\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, BooleanType, TimestampType, LongType\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5859f4",
   "metadata": {},
   "source": [
    "## Create Spark session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ef8c5b",
   "metadata": {},
   "source": [
    "spark = SparkSession.builder.enableHiveSupport().config(\"spark.sql.legacy.createHiveTableByDefault\", False).appName(\"UserInformation\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sparksql = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb7db3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/23 03:48:16 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Set the warehouse location\n",
    "warehouse_location = \"file:///home/hx152/Project/tweet_project/Dataset/spark-warehouse\"\n",
    "hivedb_location = \"file:///home/hx152/Project/tweet_project/Dataset/metastore_db\"\n",
    "# warehouse_location = \"hdfs://data/\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .enableHiveSupport() \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n",
    "    .config(\"hive.metastore.warehouse.dir\", warehouse_location) \\\n",
    "    .config(\"spark.sql.legacy.createHiveTableByDefault\", False) \\\n",
    "    .appName(\"UserInformation\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sparksql = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fed0fd",
   "metadata": {},
   "source": [
    "## Create DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc813713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(namespace='default'),\n",
       " Row(namespace='user_data'),\n",
       " Row(namespace='userinformation')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = sparksql.sql('SHOW DATABASES')\n",
    "a.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "489e5546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query = 'CREATE DATABASE IF NOT EXISTS userInformation'\n",
    "a = sparksql.sql(sql_query)\n",
    "a.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "150ae79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = sparksql.sql('Use userInformation')\n",
    "a.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab42ebda",
   "metadata": {},
   "source": [
    "## Create tables in selected DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6c2c5e75",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Sun Apr 12 18:27:26 +0000 2020',\n",
       " 'id': 1249403770360016896,\n",
       " 'id_str': '1249403770360016896',\n",
       " 'text': 'SERÁ APENAS COINCIDÊNCIA?\\n\\nApós escudo do Remo aparecer em prédio, Prefeitura divulgou que 33 pessoas com corona se… https://t.co/lCcwYH2eg5',\n",
       " 'display_text_range': [0, 140],\n",
       " 'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>',\n",
       " 'truncated': True,\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'user': {'id': 988174833849634816,\n",
       "  'id_str': '988174833849634816',\n",
       "  'name': 'TV Conservador / Metró',\n",
       "  'screen_name': 'TVConservador',\n",
       "  'location': 'Belém, Brasil',\n",
       "  'url': None,\n",
       "  'description': 'Emissora afiliada a Rede Metrópole (@cnt_pr) no estado do Pará. As notícias aqui dadas são FICTÍCIAS, não pegue corda ok 👍\\n\\n© Sistema O Conservador Ltda.',\n",
       "  'translator_type': 'none',\n",
       "  'protected': False,\n",
       "  'verified': False,\n",
       "  'followers_count': 7240,\n",
       "  'friends_count': 566,\n",
       "  'listed_count': 17,\n",
       "  'favourites_count': 18417,\n",
       "  'statuses_count': 22665,\n",
       "  'created_at': 'Sun Apr 22 21:56:54 +0000 2018',\n",
       "  'utc_offset': None,\n",
       "  'time_zone': None,\n",
       "  'geo_enabled': False,\n",
       "  'lang': None,\n",
       "  'contributors_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'profile_background_color': '000000',\n",
       "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_tile': False,\n",
       "  'profile_link_color': '1B95E0',\n",
       "  'profile_sidebar_border_color': '000000',\n",
       "  'profile_sidebar_fill_color': '000000',\n",
       "  'profile_text_color': '000000',\n",
       "  'profile_use_background_image': False,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/1245501760518701057/zUWjkVz__normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1245501760518701057/zUWjkVz__normal.jpg',\n",
       "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/988174833849634816/1585783589',\n",
       "  'default_profile': False,\n",
       "  'default_profile_image': False,\n",
       "  'following': None,\n",
       "  'follow_request_sent': None,\n",
       "  'notifications': None},\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'is_quote_status': False,\n",
       " 'extended_tweet': {'full_text': 'SERÁ APENAS COINCIDÊNCIA?\\n\\nApós escudo do Remo aparecer em prédio, Prefeitura divulgou que 33 pessoas com corona se recuperaram. Sim, 33! https://t.co/Q4HNeOJpn6',\n",
       "  'display_text_range': [0, 137],\n",
       "  'entities': {'hashtags': [],\n",
       "   'urls': [],\n",
       "   'user_mentions': [],\n",
       "   'symbols': [],\n",
       "   'media': [{'id': 1249403767126196226,\n",
       "     'id_str': '1249403767126196226',\n",
       "     'indices': [138, 161],\n",
       "     'media_url': 'http://pbs.twimg.com/media/EVbGG0iXgAI2FAm.jpg',\n",
       "     'media_url_https': 'https://pbs.twimg.com/media/EVbGG0iXgAI2FAm.jpg',\n",
       "     'url': 'https://t.co/Q4HNeOJpn6',\n",
       "     'display_url': 'pic.twitter.com/Q4HNeOJpn6',\n",
       "     'expanded_url': 'https://twitter.com/TVConservador/status/1249403770360016896/photo/1',\n",
       "     'type': 'photo',\n",
       "     'sizes': {'large': {'w': 498, 'h': 452, 'resize': 'fit'},\n",
       "      'thumb': {'w': 150, 'h': 150, 'resize': 'crop'},\n",
       "      'small': {'w': 498, 'h': 452, 'resize': 'fit'},\n",
       "      'medium': {'w': 498, 'h': 452, 'resize': 'fit'}}}]},\n",
       "  'extended_entities': {'media': [{'id': 1249403767126196226,\n",
       "     'id_str': '1249403767126196226',\n",
       "     'indices': [138, 161],\n",
       "     'media_url': 'http://pbs.twimg.com/media/EVbGG0iXgAI2FAm.jpg',\n",
       "     'media_url_https': 'https://pbs.twimg.com/media/EVbGG0iXgAI2FAm.jpg',\n",
       "     'url': 'https://t.co/Q4HNeOJpn6',\n",
       "     'display_url': 'pic.twitter.com/Q4HNeOJpn6',\n",
       "     'expanded_url': 'https://twitter.com/TVConservador/status/1249403770360016896/photo/1',\n",
       "     'type': 'photo',\n",
       "     'sizes': {'large': {'w': 498, 'h': 452, 'resize': 'fit'},\n",
       "      'thumb': {'w': 150, 'h': 150, 'resize': 'crop'},\n",
       "      'small': {'w': 498, 'h': 452, 'resize': 'fit'},\n",
       "      'medium': {'w': 498, 'h': 452, 'resize': 'fit'}}}]}},\n",
       " 'quote_count': 0,\n",
       " 'reply_count': 0,\n",
       " 'retweet_count': 0,\n",
       " 'favorite_count': 0,\n",
       " 'entities': {'hashtags': [],\n",
       "  'urls': [{'url': 'https://t.co/lCcwYH2eg5',\n",
       "    'expanded_url': 'https://twitter.com/i/web/status/1249403770360016896',\n",
       "    'display_url': 'twitter.com/i/web/status/1…',\n",
       "    'indices': [117, 140]}],\n",
       "  'user_mentions': [],\n",
       "  'symbols': []},\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'possibly_sensitive': False,\n",
       " 'filter_level': 'low',\n",
       " 'lang': 'pt',\n",
       " 'timestamp_ms': '1586716046310'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT RUN. An example of data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b16d26e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# table 'user421' add a column named 'tweet_creat_time'\n",
    "sparksql.sql('''\n",
    "            CREATE TABLE IF NOT EXISTS user422(\n",
    "             tweet_creat_time TIMESTAMP,\n",
    "             id LONG,\n",
    "             name STRING,\n",
    "             screen_name STRING,\n",
    "             verified BOOLEAN,\n",
    "             created_at TIMESTAMP,\n",
    "             followers_count INT,\n",
    "             friends_count INT,\n",
    "             listed_count INT,\n",
    "             favourites_count INT,\n",
    "             statuses_count INT\n",
    "            ) USING parquet\n",
    "            ''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "de622745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparksql.sql('''\n",
    "            CREATE TABLE IF NOT EXISTS user423(\n",
    "             tweet_create_time TIMESTAMP,\n",
    "             tweet_id LONG,\n",
    "             user_id LONG,\n",
    "             name STRING,\n",
    "             screen_name STRING,\n",
    "             location STRING,\n",
    "             url STRING,\n",
    "             description STRING,\n",
    "             verified BOOLEAN,\n",
    "             created_at TIMESTAMP,\n",
    "             followers_count INT,\n",
    "             friends_count INT,\n",
    "             listed_count INT,\n",
    "             favourites_count INT,\n",
    "             statuses_count INT \n",
    "            ) USING parquet\n",
    "            ''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7b797052",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(namespace='userinformation', tableName='basic', isTemporary=False),\n",
       " Row(namespace='userinformation', tableName='user', isTemporary=False),\n",
       " Row(namespace='userinformation', tableName='user421', isTemporary=False),\n",
       " Row(namespace='userinformation', tableName='user422', isTemporary=False),\n",
       " Row(namespace='userinformation', tableName='user423', isTemporary=False)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = sparksql.sql('SHOW TABLES')\n",
    "a.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbba42d9",
   "metadata": {},
   "source": [
    "sparksql.sql('''\n",
    "    DROP TABLE user423\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db913b7",
   "metadata": {},
   "source": [
    "## Insert User Data from the tweet data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e632c4e",
   "metadata": {},
   "source": [
    "### ----------------------- ⭐️Schames⭐️ -----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c76b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define schema for user421 table\n",
    "user_schema = StructType([\n",
    "    StructField(\"tweet_creat_time\", TimestampType()),\n",
    "    StructField(\"id\", LongType()),\n",
    "    StructField(\"name\", StringType()),\n",
    "    StructField(\"screen_name\", StringType()),\n",
    "    StructField(\"verified\", BooleanType()),\n",
    "    StructField(\"created_at\", TimestampType()),\n",
    "    StructField(\"followers_count\", IntegerType()),\n",
    "    StructField(\"friends_count\", IntegerType()),\n",
    "    StructField(\"listed_count\", IntegerType()),\n",
    "    StructField(\"favourites_count\", IntegerType()),\n",
    "    StructField(\"statuses_count\", IntegerType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fcd9b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user423_schema = StructType([\n",
    "    StructField(\"tweet_create_time\", TimestampType()),\n",
    "    StructField(\"tweet_id\", LongType()),\n",
    "    StructField(\"user_id\", LongType()),\n",
    "    StructField(\"name\", StringType()),\n",
    "    StructField(\"screen_name\", StringType()),\n",
    "    StructField(\"location\", StringType()),\n",
    "    StructField(\"url\", StringType()),\n",
    "    StructField(\"description\", StringType()),\n",
    "    StructField(\"verified\", BooleanType()),\n",
    "    StructField(\"created_at\", TimestampType()),\n",
    "    StructField(\"followers_count\", IntegerType()),\n",
    "    StructField(\"friends_count\", IntegerType()),\n",
    "    StructField(\"listed_count\", IntegerType()),\n",
    "    StructField(\"favourites_count\", IntegerType()),\n",
    "    StructField(\"statuses_count\", IntegerType())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de70491",
   "metadata": {},
   "source": [
    "### ------------------------ ⭐️Functions⭐️ ------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2edf2183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_with_df(data, table_name, table_schema):\n",
    "    datetime_format = \"%a %b %d %H:%M:%S %z %Y\"\n",
    "    tweet_creat_at_datetime = datetime.strptime(data['created_at'], datetime_format)\n",
    "    created_at_datetime = datetime.strptime(data['user']['created_at'], datetime_format)\n",
    "\n",
    "    user_data_row = [(tweet_creat_at_datetime, data['user']['id'], data['user']['name'], data['user']['screen_name'], data['user'][\"verified\"], created_at_datetime, data['user'][\"followers_count\"], data['user'][\"friends_count\"], data['user'][\"listed_count\"], data['user'][\"favourites_count\"], data['user'][\"statuses_count\"])]\n",
    "\n",
    "    if user_exist(data['user']['id'], table_name): # if already in the table\n",
    "        update_user(user_data_row, table_name)\n",
    "    else: # if does not exist in table\n",
    "        insert_user(user_data_row, table_name)\n",
    "\n",
    "def user_exist(user_id, table_name) -> bool:\n",
    "    result = spark.sql(f\"SELECT COUNT(*) as count FROM {table_name} WHERE id = {user_id}\")\n",
    "    count = result.collect()[0][\"count\"]\n",
    "    return count > 0\n",
    "\n",
    "def update_user(data_row, table_name):\n",
    "    user_id = data_row[0][1]\n",
    "    existed_ts = spark.sql(f\"SELECT tweet_creat_time FROM {table_name} WHERE id = {user_id}\").collect()\n",
    "    if len(existed_ts) > 0:\n",
    "        existed_timestamp = existed_ts[0][\"tweet_creat_time\"]\n",
    "    else:\n",
    "        existed_timestamp = None\n",
    "    new_timestamp = data_row[0][0].replace(tzinfo=None)\n",
    "    if existed_timestamp and new_timestamp and new_timestamp > existed_timestamp: # update only when timestamp is later\n",
    "        delete_user(user_id)\n",
    "        insert_user(data_row)\n",
    "        \n",
    "def insert_user(data_row, table_name, table_schema):\n",
    "    print(\"！！Inserting\")\n",
    "    user_df = spark.createDataFrame(data_row, schema=table_schema)\n",
    "    user_df.write.mode(\"append\").insertInto(table_name)\n",
    "    \n",
    "def delete_user(user_id, table_name):\n",
    "    spark.sql(f\"DELETE FROM {table_name} WHERE id = {user_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb935b32",
   "metadata": {},
   "source": [
    "### An example for insert directly with SQL query\n",
    "query = \"\"\" \\\n",
    "    INSERT INTO basic (id, name, screen_name) \\\n",
    "    VALUES (1, 'Alice', 'alice01'), \\\n",
    "           (2, 'Bob', 'bob02'), \\\n",
    "           (3, 'Charlie', 'charlie03'), \\\n",
    "           (4, 'David', 'david04') \\\n",
    "\"\"\" \\\n",
    "\\\n",
    "spark.sql(query)\n",
    "\n",
    "Using __DataFrames__ is more efficient then inserting data directly into a table using a SQL INSERT INTO statement, especially when dealing with __large amounts of data__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "58ea2b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONST DEFINITION\n",
    "DATETIME_FORMAT = \"%a %b %d %H:%M:%S %z %Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4512f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_data_type(data):\n",
    "    tweet_creat_at_datetime = datetime.strptime(data['created_at'], DATETIME_FORMAT)\n",
    "    created_at_datetime = datetime.strptime(data['user']['created_at'], DATETIME_FORMAT)\n",
    "    user_data_row = (tweet_creat_at_datetime, data['id'], data['user']['id'], data['user']['name'], data['user']['screen_name'], data['user']['location'], data['user']['url'], data['user']['description'], data['user'][\"verified\"], created_at_datetime, data['user'][\"followers_count\"], data['user'][\"friends_count\"], data['user'][\"listed_count\"], data['user'][\"favourites_count\"], data['user'][\"statuses_count\"])\n",
    "    return user_data_row\n",
    "\n",
    "def insert_with_df(df, schema, table_name):    \n",
    "    user_df = spark.createDataFrame(result, schema)\n",
    "    user_df.write.mode(\"append\").insertInto(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5a2e0501",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(\"/home/hx152/Project/tweet_project/Dataset/test_data\", \"r\") as f1:\n",
    "    \n",
    "    result = []\n",
    "    for line in f1:\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            user_data_row = unify_data_type(data)\n",
    "            result.append(user_data_row)\n",
    "            \n",
    "            if 'retweeted_status' in data:\n",
    "                data = data['retweeted_status']\n",
    "                user_data_row = unify_data_type(data)\n",
    "                result.append(user_data_row)\n",
    "                \n",
    "            if 'quoted_status' in data:\n",
    "                data = data['quoted_status']\n",
    "                user_data_row = unify_data_type(data)\n",
    "                result.append(user_data_row)\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "    # parameters: \n",
    "    df, schema, table_name = result, user423_schema, 'user423'\n",
    "    insert_with_df(df, schema, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "df240a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|number_rows|\n",
      "+-----------+\n",
      "|         13|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT count(*) number_rows FROM user423\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c23c8705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+--------------------+\n",
      "|           tweet_id|            user_id|                name|         description|\n",
      "+-------------------+-------------------+--------------------+--------------------+\n",
      "|1249403114614075400|1193535233242664960|          𝒎𝒆𝒍𝒆𝒌|🌍 / emigrant / m...|\n",
      "|1249403770435493888|         4707764075| UpsidedownTurtle 🧢|                null|\n",
      "|1249316363681910784|           14135350|    Bianna Golodryga|@CNN Senior Globa...|\n",
      "|1249403770360016896| 988174833849634816|TV Conservador / ...|Emissora afiliada...|\n",
      "|1249403767180668930|1242817830946508801|            juwelz v|Event Lyfe LLC .....|\n",
      "|1249378751349231616|           16144221|                NUFF|instagram: @nuffs...|\n",
      "|1249315454797168641|           46769281|          Gucci Mane|Major Label Recor...|\n",
      "|1249326224964345857|          268218622|       Umesh Agrawal|                null|\n",
      "|1249319407177744385|         1897514666|  Dharmendra Pradhan|Minister of Petro...|\n",
      "|1249403769567227906|1230170166614482944|          Carpe diem|Yezidin hârcı zul...|\n",
      "|1249403768023678982|1225145123920588805|               efe09|Allah'ın en değer...|\n",
      "|1249397541596286979|1087735689091928064|       Karanfil Lale|                null|\n",
      "|1249403769193779202|          101007632|         Ravin Gupta|Tweet is personal...|\n",
      "+-------------------+-------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT tweet_id, user_id, name, description FROM user423\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68cecb15",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2020, 4, 12, 18, 27, 25, tzinfo=datetime.timezone.utc),\n",
       "  1242817830946508801,\n",
       "  'juwelz v',\n",
       "  'juwelz_v',\n",
       "  False,\n",
       "  datetime.datetime(2020, 3, 25, 14, 17, 28, tzinfo=datetime.timezone.utc),\n",
       "  43,\n",
       "  118,\n",
       "  0,\n",
       "  722,\n",
       "  906),\n",
       " (datetime.datetime(2020, 4, 12, 18, 27, 25, tzinfo=datetime.timezone.utc),\n",
       "  1225145123920588805,\n",
       "  'efe09',\n",
       "  'efe0927183508',\n",
       "  False,\n",
       "  datetime.datetime(2020, 2, 5, 19, 52, 38, tzinfo=datetime.timezone.utc),\n",
       "  653,\n",
       "  983,\n",
       "  0,\n",
       "  1255,\n",
       "  4177),\n",
       " (datetime.datetime(2020, 4, 12, 18, 27, 26, tzinfo=datetime.timezone.utc),\n",
       "  101007632,\n",
       "  'Ravin Gupta',\n",
       "  'IamRaavin',\n",
       "  False,\n",
       "  datetime.datetime(2010, 1, 1, 16, 24, 24, tzinfo=datetime.timezone.utc),\n",
       "  499,\n",
       "  537,\n",
       "  2,\n",
       "  4342,\n",
       "  4038),\n",
       " (datetime.datetime(2020, 4, 12, 18, 27, 26, tzinfo=datetime.timezone.utc),\n",
       "  1230170166614482944,\n",
       "  'Carpe diem',\n",
       "  'Carpedi92670638',\n",
       "  False,\n",
       "  datetime.datetime(2020, 2, 19, 16, 40, 9, tzinfo=datetime.timezone.utc),\n",
       "  425,\n",
       "  459,\n",
       "  0,\n",
       "  8830,\n",
       "  13101),\n",
       " (datetime.datetime(2020, 4, 12, 18, 27, 26, tzinfo=datetime.timezone.utc),\n",
       "  4707764075,\n",
       "  'UpsidedownTurtle 🧢',\n",
       "  'Adakisn',\n",
       "  False,\n",
       "  datetime.datetime(2016, 1, 4, 19, 43, 48, tzinfo=datetime.timezone.utc),\n",
       "  76,\n",
       "  82,\n",
       "  1,\n",
       "  6041,\n",
       "  7471),\n",
       " (datetime.datetime(2020, 4, 12, 18, 27, 26, tzinfo=datetime.timezone.utc),\n",
       "  988174833849634816,\n",
       "  'TV Conservador / Metró',\n",
       "  'TVConservador',\n",
       "  False,\n",
       "  datetime.datetime(2018, 4, 22, 21, 56, 54, tzinfo=datetime.timezone.utc),\n",
       "  7240,\n",
       "  566,\n",
       "  17,\n",
       "  18417,\n",
       "  22665)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b63778c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|                 id|                name|\n",
      "+-------------------+--------------------+\n",
      "| 988174833849634816|TV Conservador / ...|\n",
      "|         4707764075| UpsidedownTurtle 🧢|\n",
      "|1230170166614482944|          Carpe diem|\n",
      "|          101007632|         Ravin Gupta|\n",
      "|1225145123920588805|               efe09|\n",
      "|1242817830946508801|            juwelz v|\n",
      "+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT id, name FROM user421\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f32107",
   "metadata": {},
   "source": [
    "# ---------------------- Test code ↓ ↓ ↓------DO NOT RUN----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f01aeb6",
   "metadata": {},
   "source": [
    "## Insert data into tables with the required schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ec1c78cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test function user_exist\n",
    "user_exist(988174833849634816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "46ce94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "def user_exist(user_id) -> bool:\n",
    "    result = spark.sql(f\"SELECT created_at FROM user WHERE id = {user_id}\")\n",
    "    rows = result.collect()\n",
    "\n",
    "    if len(rows) > 0:\n",
    "        created_at = rows[0][\"created_at\"]\n",
    "        return created_at\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "261db211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 4, 12, 18, 27, 25, tzinfo=datetime.timezone.utc)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "datetime_format = \"%a %b %d %H:%M:%S %z %Y\"\n",
    "tweet_creat_at_datetime = datetime.strptime(data['created_at'], datetime_format)\n",
    "tweet_creat_at_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d29c0748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "a = spark.sql(f\"SELECT tweet_creat_time FROM user421 WHERE id = 25235\")\n",
    "a.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39533ae9",
   "metadata": {},
   "source": [
    "### save data_row into dataframe(df) first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce1ce82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+-------------+--------+-------------------+---------------+-------------+------------+----------------+--------------+\n",
      "|                id|                name|  screen_name|verified|         created_at|followers_count|friends_count|listed_count|favourites_count|statuses_count|\n",
      "+------------------+--------------------+-------------+--------+-------------------+---------------+-------------+------------+----------------+--------------+\n",
      "|988174833849634816|TV Conservador / ...|TVConservador|   false|2018-04-22 21:56:54|           7240|          566|          17|           18417|         22665|\n",
      "+------------------+--------------------+-------------+--------+-------------------+---------------+-------------+------------+----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_name = \"user\"\n",
    "\n",
    "user_df.write \\\n",
    "    .mode(\"append\") \\\n",
    "    .insertInto(table_name)\n",
    "\n",
    "spark.sql(\"SELECT * FROM user\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b088168c",
   "metadata": {},
   "source": [
    "## ----------------------- Write a recurence function for nested data -----------------------\n",
    "### Extract user information in quoted tweet or retweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e587cbc1",
   "metadata": {},
   "source": [
    "def insert_func():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35775cfb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1563028047.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    if no more nested:\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# pseudo-code\n",
    "def extract_nested_info():\n",
    "    if no more nested:\n",
    "        store what we get so far\n",
    "    else:\n",
    "        extract_nested_info() # input: the inside data of the nested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363720d4",
   "metadata": {},
   "source": [
    "### Created the db and tables, now we can insert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11aff91f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 988174833849634816,\n",
       " 'id_str': '988174833849634816',\n",
       " 'name': 'TV Conservador / Metró',\n",
       " 'screen_name': 'TVConservador',\n",
       " 'location': 'Belém, Brasil',\n",
       " 'url': None,\n",
       " 'description': 'Emissora afiliada a Rede Metrópole (@cnt_pr) no estado do Pará. As notícias aqui dadas são FICTÍCIAS, não pegue corda ok 👍\\n\\n© Sistema O Conservador Ltda.',\n",
       " 'translator_type': 'none',\n",
       " 'protected': False,\n",
       " 'verified': False,\n",
       " 'followers_count': 7240,\n",
       " 'friends_count': 566,\n",
       " 'listed_count': 17,\n",
       " 'favourites_count': 18417,\n",
       " 'statuses_count': 22665,\n",
       " 'created_at': 'Sun Apr 22 21:56:54 +0000 2018',\n",
       " 'utc_offset': None,\n",
       " 'time_zone': None,\n",
       " 'geo_enabled': False,\n",
       " 'lang': None,\n",
       " 'contributors_enabled': False,\n",
       " 'is_translator': False,\n",
       " 'profile_background_color': '000000',\n",
       " 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       " 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       " 'profile_background_tile': False,\n",
       " 'profile_link_color': '1B95E0',\n",
       " 'profile_sidebar_border_color': '000000',\n",
       " 'profile_sidebar_fill_color': '000000',\n",
       " 'profile_text_color': '000000',\n",
       " 'profile_use_background_image': False,\n",
       " 'profile_image_url': 'http://pbs.twimg.com/profile_images/1245501760518701057/zUWjkVz__normal.jpg',\n",
       " 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1245501760518701057/zUWjkVz__normal.jpg',\n",
       " 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/988174833849634816/1585783589',\n",
       " 'default_profile': False,\n",
       " 'default_profile_image': False,\n",
       " 'following': None,\n",
       " 'follow_request_sent': None,\n",
       " 'notifications': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# try extract first user information\n",
    "\n",
    "result = []\n",
    "#insert path and replace name of the file below as needed\n",
    "with open(\"/home/hx152/Project/tweet_project/Dataset/test_data\", \"r\") as f1:\n",
    "    for line in f1:\n",
    "        result += [line]\n",
    "\n",
    "data = json.loads(result[10])\n",
    "data['user']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a3fded2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include the schema while creating tables\n",
    "sparksql.sql('''\n",
    "            CREATE TABLE IF NOT EXISTS basic(\n",
    "             id Long,\n",
    "             name STRING,\n",
    "             screen_name STRING\n",
    "            ) USING parquet\n",
    "            ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70b94fb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datetime_format = \"%a %b %d %H:%M:%S %z %Y\"\n",
    "created_at_datetime = datetime.strptime(data['user']['created_at'], datetime_format)\n",
    "\n",
    "user_data_row = [(data['user']['id'], data['user']['name'], data['user']['screen_name'], data['user'][\"verified\"], created_at_datetime, data['user'][\"followers_count\"], data['user'][\"friends_count\"], data['user'][\"listed_count\"], data['user'][\"favourites_count\"], data['user'][\"statuses_count\"])]\n",
    "\n",
    "user_df = spark.createDataFrame(user_data_row, schema=user_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43ab31c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_schema = StructType([\n",
    "    StructField(\"id\", LongType()),\n",
    "    StructField(\"name\", StringType()),\n",
    "    StructField(\"screen_name\", StringType())\n",
    "    ])\n",
    "\n",
    "data_row = [(data['user']['id'], data['user']['name'], data['user']['screen_name'])]\n",
    "\n",
    "df = spark.createDataFrame(data_row, schema=basic_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a43078ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = data['user']['id']\n",
    "name = data['user']['name']\n",
    "screen_name = data['user']['screen_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a08cad3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=804046791348015107, name='Bi Sex Uau', screen_name='B_King69')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_data_row = [(id, name, screen_name)]\n",
    "df = spark.createDataFrame(one_data_row, schema=basic_schema)\n",
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd55d2d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+-------------+\n",
      "|                id|                name|  screen_name|\n",
      "+------------------+--------------------+-------------+\n",
      "|988174833849634816|TV Conservador / ...|TVConservador|\n",
      "+------------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# an example of insert from df\n",
    "table_name = \"basic\"\n",
    "\n",
    "df.write \\\n",
    "    .mode(\"append\") \\\n",
    "    .insertInto(table_name)\n",
    "\n",
    "# check what records have been included in basic table\n",
    "spark.sql(\"SELECT * FROM basic\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "184f21cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=988174833849634816, name='TV Conservador / Metró', screen_name='TVConservador')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another way to check what records have been included in basic table\n",
    "query = '''\n",
    "    SELECT *\n",
    "    FROM basic\n",
    "'''\n",
    "a = sparksql.sql(query)\n",
    "a.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e7ecd",
   "metadata": {},
   "source": [
    "### --------------------------------------- other test code ---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e759ec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = ''\n",
    "a = sparksql.sql(q)\n",
    "a.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1d7b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define schema for user table\n",
    "user_schema = StructType([\n",
    "    StructField(\"id\", IntegerType()),\n",
    "    StructField(\"id_str\", StringType()),\n",
    "    StructField(\"name\", StringType()),\n",
    "    StructField(\"screen_name\", StringType()),\n",
    "    StructField(\"location\", StringType()),\n",
    "    StructField(\"url\", StringType()),\n",
    "    StructField(\"description\", StringType()),\n",
    "    StructField(\"translator_type\", StringType()),\n",
    "    StructField(\"protected\", BooleanType()),\n",
    "    StructField(\"verified\", BooleanType()),\n",
    "    StructField(\"created_at\", TimestampType()),\n",
    "    StructField(\"utc_offset\", StringType()),\n",
    "    StructField(\"time_zone\", StringType()),\n",
    "    StructField(\"geo_enabled\", BooleanType()),\n",
    "    StructField(\"lang\", StringType()),\n",
    "    StructField(\"contributors_enabled\", BooleanType()),\n",
    "    StructField(\"is_translator\", BooleanType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aafa0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7d3df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define schema for user_profile table\n",
    "profile_schema = StructType([\n",
    "    StructField(\"id\", IntegerType()),\n",
    "    StructField(\"followers_count\", IntegerType()),\n",
    "    StructField(\"friends_count\", IntegerType()),\n",
    "    StructField(\"listed_count\", IntegerType()),\n",
    "    StructField(\"favourites_count\", IntegerType()),\n",
    "    StructField(\"statuses_count\", IntegerType()),\n",
    "    StructField(\"profile_background_color\", StringType()),\n",
    "    StructField(\"profile_background_image_url\", StringType()),\n",
    "    StructField(\"profile_background_image_url_https\", StringType()),\n",
    "    StructField(\"profile_background_tile\", BooleanType()),\n",
    "    StructField(\"profile_link_color\", StringType()),\n",
    "    StructField(\"profile_sidebar_border_color\", StringType()),\n",
    "    StructField(\"profile_sidebar_fill_color\", StringType()),\n",
    "    StructField(\"profile_text_color\", StringType()),\n",
    "    StructField(\"profile_use_background_image\", BooleanType()),\n",
    "    StructField(\"profile_image_url\", StringType()),\n",
    "    StructField(\"profile_image_url_https\", StringType()),\n",
    "    StructField(\"profile_banner_url\", StringType()),\n",
    "    StructField(\"default_profile\", BooleanType()),\n",
    "    StructField(\"default_profile_image\", BooleanType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56fdfb64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4153117\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "print(len(result))\n",
    "#insert path and replace name of the file below as needed\n",
    "with open(\"/home/hx152/Project/tweet_project/Dataset/corona-out-3\", \"r\") as f1:\n",
    "    for line in f1:\n",
    "        result += [line]\n",
    "\n",
    "for i in range(num_record):\n",
    "    try:\n",
    "        data = json.loads(result[i])\n",
    "        result += data['user']\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd900e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "username =  \"x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6807cd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert username x\n"
     ]
    }
   ],
   "source": [
    "print(\"insert username \" + username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0049cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
